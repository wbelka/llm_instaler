#!/usr/bin/env python3
"""Fix torch vulnerability issue for models."""

import subprocess
import sys
from pathlib import Path


def fix_vulnerability(model_path: Path):
    """Fix torch vulnerability by using safetensors or updating transformers."""
    
    pip_path = model_path / ".venv" / "bin" / "pip"
    python_path = model_path / ".venv" / "bin" / "python"
    
    if not pip_path.exists():
        pip_path = model_path / ".venv" / "Scripts" / "pip.exe"
        python_path = model_path / ".venv" / "Scripts" / "python.exe"
    
    print(f"Fixing torch vulnerability in: {model_path}")
    
    # Option 1: Try to use CPU version of torch 2.6+
    print("\nOption 1: Trying to install CPU version of torch 2.6+...")
    cmd = [str(pip_path), "install", "torch>=2.6.0", "--index-url", "https://download.pytorch.org/whl/cpu"]
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        print("✓ Installed CPU torch 2.6+")
        # Now install CUDA version on top
        print("Installing CUDA support...")
        cmd = [str(pip_path), "install", "torch", "torchvision", "torchaudio", 
               "--index-url", "https://download.pytorch.org/whl/cu121", "--upgrade", "--force-reinstall"]
        subprocess.run(cmd, capture_output=True, text=True)
    
    # Option 2: Set environment variable to bypass the check (NOT RECOMMENDED for production)
    print("\nOption 2: Setting environment variable to bypass check...")
    env_file = model_path / ".env"
    with open(env_file, 'w') as f:
        f.write("# Bypass torch vulnerability check - USE WITH CAUTION\n")
        f.write("TRANSFORMERS_ALLOW_UNSAFE_TORCH=1\n")
    
    print(f"✓ Created .env file at {env_file}")
    
    # Option 3: Convert model weights to safetensors format
    print("\nOption 3: Checking for safetensors weights...")
    model_dir = model_path / "model"
    
    # Check if there are .bin files
    bin_files = list(model_dir.glob("*.bin"))
    safetensor_files = list(model_dir.glob("*.safetensors"))
    
    if bin_files and not safetensor_files:
        print(f"Found {len(bin_files)} .bin files but no .safetensors files")
        print("Consider downloading safetensors version of the model")
    elif safetensor_files:
        print(f"✓ Found {len(safetensor_files)} .safetensors files - these are safe to load")
    
    # Update start.sh to include the environment variable
    start_sh = model_path / "start.sh"
    if start_sh.exists():
        content = start_sh.read_text()
        if "TRANSFORMERS_ALLOW_UNSAFE_TORCH" not in content:
            # Add export before starting the server
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if "uvicorn" in line or "python" in line and "serve_api" in line:
                    lines.insert(i, "export TRANSFORMERS_ALLOW_UNSAFE_TORCH=1")
                    break
            
            start_sh.write_text('\n'.join(lines))
            print("✓ Updated start.sh to include environment variable")
    
    print("\n✓ Applied fixes. The model should now start despite the torch version.")
    print("⚠️  WARNING: Using TRANSFORMERS_ALLOW_UNSAFE_TORCH=1 bypasses security checks.")
    print("   This is a temporary workaround. Consider upgrading to torch 2.6+ when available for CUDA 12.1")


def main():
    if len(sys.argv) < 2:
        print("Usage: python fix_torch_vulnerability.py <model_path>")
        sys.exit(1)
    
    model_path = Path(sys.argv[1])
    fix_vulnerability(model_path)


if __name__ == "__main__":
    main()