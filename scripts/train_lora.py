#!/usr/bin/env python3
"""
Universal Smart Fine-Tuning Script with LoRA
Uses handlers for model-specific training configurations
Generated by LLM Installer
"""

import os
import sys
import json
import time
import torch
import logging
import argparse
import subprocess
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import matplotlib.pyplot as plt
from dataclasses import dataclass, asdict
import numpy as np
import warnings
from tqdm import tqdm

# Suppress some warnings
warnings.filterwarnings("ignore", category=UserWarning, module="transformers")
warnings.filterwarnings("ignore", category=UserWarning, module="torch")

# Disable flash attention for training to avoid compatibility issues
os.environ["TRANSFORMERS_USE_FLASH_ATTENTION"] = "0"

# Add installer path to sys.path
installer_path = Path(__file__).parent / "core"
if installer_path.exists():
    sys.path.insert(0, str(installer_path))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('training.log')
    ]
)
logger = logging.getLogger(__name__)


class TrainingMetrics:
    """Track training metrics for auto-stop decisions."""
    
    def __init__(self):
        self.train_losses = []
        self.val_losses = []
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.evaluations = 0
        self.circular_epochs = 0
        self.start_time = time.time()
        
    def update(self, train_loss: float, val_loss: float):
        """Update metrics with new values."""
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        self.evaluations += 1
        
        # Check if improved
        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.patience_counter = 0
            return True
        else:
            self.patience_counter += 1
            return False
    
    def calculate_trend(self, values: List[float], window: int = 5) -> float:
        """Calculate trend through linear regression."""
        if len(values) < window:
            return 0.0
        
        recent = values[-window:]
        x = np.arange(len(recent))
        slope, _ = np.polyfit(x, recent, 1)
        
        return slope
    
    def check_overfitting(self, threshold: float = 0.1) -> Tuple[bool, str]:
        """Check for overfitting."""
        if self.evaluations < 5:
            return False, "insufficient_data"
        
        # Analyze trend
        val_trend = self.calculate_trend(self.val_losses)
        
        # Analyze gap
        recent_train = np.mean(self.train_losses[-5:])
        recent_val = np.mean(self.val_losses[-5:])
        
        # Handle edge cases
        if recent_train < 1e-6:  # Practically zero
            if recent_val < 1e-6:
                # Both are near zero - perfect fit, no overfitting
                return False, "perfect_fit"
            else:
                # Train is zero but val is not - likely overfitting
                return True, "severe_overfitting"
        
        # Calculate relative gap
        gap = (recent_val - recent_train) / recent_train
        
        # Decision based on trend and gap
        if val_trend > 0.001 and gap > threshold:
            if gap > 0.5:
                return True, "severe_overfitting"
            else:
                return True, "moderate_overfitting"
        
        # Additional check for text generation - look at perplexity
        if recent_val > 1.0:  # Likely a text generation task (higher loss)
            # Check if validation perplexity is increasing significantly
            val_perplexity = np.exp(recent_val)
            if val_perplexity > 100 and val_trend > 0.01:
                return True, "perplexity_explosion"
        
        return False, "no_overfitting"
    
    def get_status_string(self) -> str:
        """Get formatted status string."""
        elapsed = time.time() - self.start_time
        elapsed_str = f"{int(elapsed//3600):02d}:{int((elapsed%3600)//60):02d}:{int(elapsed%60):02d}"
        
        status_parts = [
            f"ðŸ“Š Evaluation #{self.evaluations}",
            f"â±ï¸  Time: {elapsed_str}",
            f"ðŸ“‰ Train Loss: {self.train_losses[-1]:.4f}" if self.train_losses else "",
            f"ðŸ“ˆ Val Loss: {self.val_losses[-1]:.4f}" if self.val_losses else "",
            f"ðŸŽ¯ Best Val: {self.best_val_loss:.4f}",
            f"â³ Patience: {self.patience_counter}"
        ]
        
        # Add perplexity for text generation tasks (when loss > 1)
        if self.val_losses and self.val_losses[-1] > 1.0:
            perplexity = np.exp(self.val_losses[-1])
            status_parts.insert(4, f"ðŸ“– Perplexity: {perplexity:.1f}")
        
        return " | ".join(filter(None, status_parts))


def load_model_and_tokenizer(model_path: str, training_config: Dict[str, Any], model_info: Dict[str, Any]):
    """Load model, tokenizer, and prepare for training using handlers."""
    # Import here to avoid circular imports
    from model_loader import load_model, get_handler
    
    # Get handler
    handler = get_handler(model_info)
    if not handler:
        # Fallback to base handler
        from handlers.base import BaseHandler
        handler = BaseHandler(model_info)
        logger.warning("No specific handler found, using base handler")
    
    # Get training parameters from handler
    training_params = handler.get_training_parameters()
    logger.info(f"Using handler: {handler.__class__.__name__}")
    logger.info(f"Handler training params: {training_params}")
    
    # Load model and tokenizer (without LoRA for training)
    # Disable flash attention for training
    os.environ["USE_FLASH_ATTENTION"] = "0"
    os.environ["FLASH_ATTENTION_SKIP_RESHAPE"] = "1"
    
    try:
        model, tokenizer = load_model(
            model_info,
            model_path=model_path,
            device=training_config.get('device', 'auto'),
            dtype=training_config.get('dtype', 'auto'),
            load_in_8bit=training_config.get('use_8bit', False),
            load_in_4bit=training_config.get('use_4bit', False),
            load_lora=False,  # Don't load existing LoRA for training
            use_flash_attention_2=False  # Explicitly disable flash attention
        )
    except (ImportError, Exception) as e:
        if "flash_attn" in str(e) or "_ZN3c105ErrorC2ENS_14SourceLocationE" in str(e):
            logger.warning("Flash attention import error, patching transformers to disable it")
            
            # Monkey patch transformers to prevent flash_attn import
            import sys
            import types
            
            # Create dummy flash_attn module
            dummy_flash_attn = types.ModuleType('flash_attn')
            sys.modules['flash_attn'] = dummy_flash_attn
            sys.modules['flash_attn.bert_padding'] = types.ModuleType('flash_attn.bert_padding')
            sys.modules['flash_attn.flash_attn_interface'] = types.ModuleType('flash_attn.flash_attn_interface')
            
            # Add dummy functions to prevent import errors
            sys.modules['flash_attn.bert_padding'].index_first_axis = lambda x, y: x
            sys.modules['flash_attn.bert_padding'].pad_input = lambda x, y, z: (x, y, z)
            sys.modules['flash_attn.bert_padding'].unpad_input = lambda x, y: x
            
            # Force transformers to think flash_attn is not available
            import transformers.utils.import_utils as import_utils
            import_utils._flash_attn_2_available = False
            
            # Clear any cached imports
            for module in list(sys.modules.keys()):
                if 'qwen3' in module or 'modeling_flash_attention' in module:
                    del sys.modules[module]
            
            model, tokenizer = load_model(
                model_info,
                model_path=model_path,
                device=training_config.get('device', 'auto'),
                dtype=training_config.get('dtype', 'auto'),
                load_in_8bit=training_config.get('use_8bit', False),
                load_in_4bit=training_config.get('use_4bit', False),
                load_lora=False,  # Don't load existing LoRA for training
                use_flash_attention_2=False
            )
        else:
            raise
    
    # Prepare model for training using handler
    model = handler.prepare_model_for_training(model, training_config)
    
    # Setup tokenizer using handler config
    tokenizer_config = handler.get_tokenizer_config()
    for key, value in tokenizer_config.items():
        if hasattr(tokenizer, key):
            setattr(tokenizer, key, value)
    
    # Add padding token if needed
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    return model, tokenizer, handler, training_params


def setup_lora(model, training_config: Dict[str, Any], training_params: Dict[str, Any]):
    """Setup LoRA/QLoRA for the model."""
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType
    
    # Prepare model for k-bit training if using quantization
    if training_config.get('use_8bit') or training_config.get('use_4bit'):
        model = prepare_model_for_kbit_training(model)
    
    # Get target modules from handler or use config
    target_modules = training_params.get('lora_target_modules')
    if not target_modules:
        target_modules = training_config.get('lora_target_modules', ["q_proj", "v_proj"])
    
    logger.info(f"LoRA target modules: {target_modules}")
    
    # Create LoRA config
    lora_config = LoraConfig(
        r=training_config['lora_r'],
        lora_alpha=training_config['lora_alpha'],
        target_modules=target_modules,
        lora_dropout=training_config['lora_dropout'],
        bias="none",
        task_type=TaskType.CAUSAL_LM,
        modules_to_save=training_params.get('lora_modules_to_save'),
    )
    
    # Apply LoRA
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    return model


def load_dataset(data_path: str, training_config: Dict[str, Any], tokenizer, handler_params: Dict[str, Any]):
    """Load and prepare dataset."""
    from dataset_manager import DatasetManager
    from datasets import Dataset
    import glob
    
    # Create dataset manager
    manager = DatasetManager(
        model_type=training_config.get('model_type', ''),
        model_family=training_config.get('model_family', '')
    )
    
    # Check supported formats from handler
    supported_formats = handler_params.get('dataset_formats', ['alpaca', 'chat', 'completion', 'text'])
    logger.info(f"Handler supported formats: {supported_formats}")
    
    # Parse data path - handle comma-separated list or glob patterns
    data_paths = []
    if ',' in data_path:
        # Comma-separated list
        data_paths = [p.strip() for p in data_path.split(',')]
        logger.info(f"Loading from {len(data_paths)} specified files")
    elif '*' in data_path:
        # Glob pattern
        data_paths = glob.glob(data_path)
        logger.info(f"Found {len(data_paths)} files matching pattern: {data_path}")
    else:
        # Single path (file or directory)
        data_paths = data_path
    
    # Load data
    train_data, val_data = manager.load_dataset(
        data_paths,
        format=training_config.get('dataset_format', 'auto'),
        validation_split=training_config.get('validation_split', 0.1),
        max_examples=training_config.get('max_examples'),
        shuffle=True
    )
    
    # Prepare for model
    train_data = manager.prepare_for_model(train_data, tokenizer)
    val_data = manager.prepare_for_model(val_data, tokenizer)
    
    # Convert to HF datasets
    train_dataset = Dataset.from_list(train_data)
    val_dataset = Dataset.from_list(val_data) if val_data else None
    
    # Tokenize
    def tokenize_function(examples):
        return tokenizer(
            examples['text'],
            truncation=True,
            padding='max_length',
            max_length=training_config.get('max_seq_length', 2048)
        )
    
    train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=['text'])
    if val_dataset:
        val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=['text'])
    
    return train_dataset, val_dataset


class SmartTrainer:
    """Custom trainer with auto-stop and circular training."""
    
    def __init__(self, model, tokenizer, train_dataset, val_dataset, 
                 training_config, output_dir, handler_params):
        self.model = model
        self.tokenizer = tokenizer
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.training_config = training_config
        self.output_dir = Path(output_dir)
        self.metrics = TrainingMetrics()
        self.handler_params = handler_params
        
        # Adjust overfitting threshold based on task type
        self._adjust_thresholds_for_task()
        
        # Setup training
        self._setup_training()
    
    def _adjust_thresholds_for_task(self):
        """Adjust training thresholds based on task type."""
        # Skip adjustments if force_epochs is enabled
        if self.training_config.get('force_epochs', False):
            logger.info("Force epochs enabled - auto-stop features disabled")
            return
            
        dataset_format = self.training_config.get('dataset_format', 'auto')
        model_type = self.training_config.get('model_type', '')
        
        # Text generation tasks need more lenient thresholds
        if dataset_format in ['text', 'completion'] or 'language-model' in model_type:
            # Only adjust if using default values
            if self.training_config.get('overfitting_threshold', 0.1) == 0.1:
                self.training_config['overfitting_threshold'] = 0.2  # 20% gap is OK for text gen
                logger.info("Adjusted overfitting threshold to 0.2 for text generation task")
            
            # Adjust patience as text generation converges slower
            if self.training_config.get('patience', 3) == 3:
                self.training_config['patience'] = 5
                logger.info("Adjusted patience to 5 for text generation task")
    
    def _setup_training(self):
        """Setup training components."""
        from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling
        
        # Check if flash attention is supported
        use_flash_attention = (
            self.handler_params.get('supports_flash_attention', True) and 
            not (self.training_config.get('use_8bit') or self.training_config.get('use_4bit'))
        )
        
        # Create training arguments
        training_args = TrainingArguments(
            output_dir=str(self.output_dir / "checkpoints"),
            num_train_epochs=self.training_config['num_train_epochs'],
            per_device_train_batch_size=self.training_config['batch_size'],
            per_device_eval_batch_size=self.training_config['batch_size'],
            gradient_accumulation_steps=self.training_config['gradient_accumulation_steps'],
            warmup_ratio=self.training_config['warmup_ratio'],
            weight_decay=self.training_config['weight_decay'],
            logging_dir=str(self.output_dir / "logs"),
            logging_steps=self.training_config['logging_steps'],
            eval_strategy=self.training_config['eval_strategy'],  # Changed from evaluation_strategy
            eval_steps=self.training_config['eval_steps'],
            save_strategy=self.training_config['save_strategy'],
            save_steps=self.training_config['save_steps'],
            save_total_limit=self.training_config['save_total_limit'],
            load_best_model_at_end=self.training_config['load_best_model_at_end'],
            metric_for_best_model="loss",
            greater_is_better=False,
            report_to=self.training_config['report_to'],
            remove_unused_columns=False,
            label_names=["labels"],
            learning_rate=self.training_config['learning_rate'],
            lr_scheduler_type=self.training_config['lr_scheduler_type'],
            optim=self.training_config['optimizer'],
            gradient_checkpointing=self.training_config['gradient_checkpointing'],
            # Precision - use handler recommended if available
            fp16=(self.training_config['mixed_precision'] == 'fp16' and 
                  self.handler_params.get('training_precision', 'auto') != 'bf16'),
            bf16=(self.training_config['mixed_precision'] == 'bf16' or 
                  self.handler_params.get('training_precision', 'auto') == 'bf16'),
            # Resume
            resume_from_checkpoint=self.training_config.get('resume_from_checkpoint'),
        )
        
        # Data collator
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.tokenizer,
            mlm=False,
            pad_to_multiple_of=8
        )
        
        # Create trainer with custom callback
        auto_stop_callback = AutoStopCallback(self)
        self.trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=self.train_dataset,
            eval_dataset=self.val_dataset,
            data_collator=data_collator,
            processing_class=self.tokenizer,  # Changed from tokenizer to processing_class
            callbacks=[auto_stop_callback._callback],
        )
    
    def train(self):
        """Run training with smart features."""
        if self.training_config['circular_training']:
            self._circular_training()
        else:
            self._standard_training()
    
    def _standard_training(self):
        """Standard training."""
        print("ðŸš€ Starting training...")
        self.trainer.train(resume_from_checkpoint=self.training_config.get('resume_from_checkpoint'))
        
        # Save final model
        self.save_final_model()
        
        # Plot training history
        self.plot_training_history()
    
    def _circular_training(self):
        """Circular training through dataset."""
        print("ðŸ”„ Starting circular training...")
        
        max_epochs = self.training_config['max_circular_epochs']
        original_epochs = self.training_config['num_train_epochs']
        
        for cycle in range(max_epochs):
            print(f"\nðŸ” Circular training cycle {cycle + 1}/{max_epochs}")
            
            # Train for one epoch
            self.trainer.args.num_train_epochs = 1
            self.trainer.train(resume_from_checkpoint=cycle > 0)
            
            # Check if should stop
            if hasattr(self.trainer.state, 'should_training_stop') and self.trainer.state.should_training_stop:
                print("Training stopped by callback")
                break
            
            # Check for perfect loss - adjust threshold based on task type
            if self.training_config.get('early_stop_on_perfect', True) and not self.training_config.get('force_epochs', False):
                # Different thresholds for different tasks
                dataset_format = self.training_config.get('dataset_format', 'auto')
                if dataset_format in ['text', 'completion'] or 'language-model' in self.training_config.get('model_type', ''):
                    perfect_threshold = 0.5  # More realistic for text generation
                else:
                    perfect_threshold = 0.01  # Strict for QA/instruction tasks
                
                if self.metrics.train_losses and self.metrics.train_losses[-1] < perfect_threshold:
                    print(f"âœ¨ Excellent loss achieved ({self.metrics.train_losses[-1]:.4f})! Stopping...")
                    break
            
            # Increase batch size for next cycle
            if cycle < max_epochs - 1:
                multiplier = self.training_config.get('circular_batch_multiplier', 2)
                new_batch_size = min(
                    self.trainer.args.per_device_train_batch_size * multiplier,
                    32  # Max batch size
                )
                if new_batch_size != self.trainer.args.per_device_train_batch_size:
                    self.trainer.args.per_device_train_batch_size = new_batch_size
                    print(f"ðŸ“ˆ Increased batch size to {new_batch_size}")
        
        # Save final model
        self.save_final_model()
        
        # Plot training history
        self.plot_training_history()
    
    def save_best_model(self):
        """Save best model."""
        best_path = self.output_dir / "best"
        best_path.mkdir(parents=True, exist_ok=True)
        
        self.model.save_pretrained(best_path)
        self.tokenizer.save_pretrained(best_path)
        
        # Save training state
        state = {
            'best_val_loss': self.metrics.best_val_loss,
            'evaluations': self.metrics.evaluations,
            'train_losses': self.metrics.train_losses,
            'val_losses': self.metrics.val_losses,
        }
        with open(best_path / "training_state.json", 'w') as f:
            json.dump(state, f, indent=2)
    
    def save_final_model(self):
        """Save final model to lora directory."""
        print("\nðŸ’¾ Saving final model...")
        
        # Save to lora directory
        lora_path = self.output_dir
        lora_path.mkdir(parents=True, exist_ok=True)
        
        self.model.save_pretrained(lora_path)
        
        # Save adapter config with detailed info
        adapter_config = {
            'base_model': self.training_config.get('model_id', 'unknown'),
            'created_at': datetime.now().isoformat(),
            'training_config': {k: v for k, v in self.training_config.items() 
                              if k not in ['model', 'tokenizer']},  # Exclude non-serializable
            'handler_params': self.handler_params,
            'final_metrics': {
                'best_val_loss': self.metrics.best_val_loss,
                'total_evaluations': self.metrics.evaluations,
                'training_time': time.time() - self.metrics.start_time,
                'final_train_loss': self.metrics.train_losses[-1] if self.metrics.train_losses else None,
                'final_val_loss': self.metrics.val_losses[-1] if self.metrics.val_losses else None,
            }
        }
        
        with open(lora_path / "adapter_info.json", 'w') as f:
            json.dump(adapter_config, f, indent=2)
        
        print(f"âœ… Model saved to {lora_path}")
    
    def plot_training_history(self):
        """Plot and save training history."""
        if len(self.metrics.train_losses) < 2:
            return
        
        plt.figure(figsize=(10, 6))
        plt.plot(self.metrics.train_losses, label='Train Loss', alpha=0.8)
        if self.metrics.val_losses:
            plt.plot(self.metrics.val_losses, label='Validation Loss', alpha=0.8)
        
        plt.xlabel('Evaluation Step')
        plt.ylabel('Loss')
        plt.title('Training History')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plot_path = self.output_dir / "training_history.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"ðŸ“Š Training plot saved to {plot_path}")


class AutoStopCallback:
    """Callback for auto-stop logic."""
    
    def __init__(self, smart_trainer):
        from transformers import TrainerCallback
        
        self.smart_trainer = smart_trainer
        self.last_eval_step = 0
        
        # Create the actual callback class
        class _AutoStopCallback(TrainerCallback):
            def __init__(self, parent):
                self.parent = parent
            
            def on_evaluate(self, args, state, control, metrics=None, **kwargs):
                """Called after evaluation."""
                if metrics and state.global_step > self.parent.last_eval_step:
                    self.parent.last_eval_step = state.global_step
                    
                    # Update metrics - get average train loss from recent history
                    train_losses = [log.get('loss', 0) for log in state.log_history 
                                   if 'loss' in log and log.get('loss') is not None]
                    train_loss = np.mean(train_losses[-10:]) if train_losses else 0
                    val_loss = metrics.get('eval_loss', 0)
                    
                    improved = self.parent.smart_trainer.metrics.update(train_loss, val_loss)
                    
                    # Print status
                    print(f"\n{self.parent.smart_trainer.metrics.get_status_string()}")
                    
                    # Skip auto-stop checks if force_epochs is enabled
                    if self.parent.smart_trainer.training_config.get('force_epochs', False):
                        print("ðŸ”’ Force epochs mode - ignoring auto-stop conditions")
                    else:
                        # Check overfitting
                        is_overfitting, reason = self.parent.smart_trainer.metrics.check_overfitting(
                            self.parent.smart_trainer.training_config['overfitting_threshold']
                        )
                        
                        if is_overfitting:
                            print(f"âš ï¸  Detected {reason}! Stopping training...")
                            control.should_training_stop = True
                        
                        # Check patience
                        if self.parent.smart_trainer.metrics.patience_counter >= self.parent.smart_trainer.training_config['patience']:
                            print(f"â¹ï¸  No improvement for {self.parent.smart_trainer.training_config['patience']} evaluations. Stopping...")
                            control.should_training_stop = True
                    
                    # Save best model
                    if improved:
                        print("ðŸ’¾ New best model! Saving...")
                        self.parent.smart_trainer.save_best_model()
                
                return control
        
        # Create instance
        self._callback = _AutoStopCallback(self)


def test_model(model_path: str, lora_path: str, test_prompt: str, handler_params: Dict[str, Any]):
    """Test the trained model."""
    print("\nðŸ§ª Testing trained model...")
    
    from model_loader import load_model
    
    # Load model info - check both locations
    model_info_path = Path("model_info.json")
    if not model_info_path.exists():
        model_info_path = Path(model_path) / "model_info.json"
    
    with open(model_info_path, 'r') as f:
        model_info = json.load(f)
    
    # Load model with LoRA
    model, tokenizer = load_model(
        model_info,
        model_path=model_path,
        lora_path=lora_path,
        load_lora=True
    )
    
    # Generate
    inputs = tokenizer(test_prompt, return_tensors="pt")
    if torch.cuda.is_available():
        inputs = {k: v.cuda() for k, v in inputs.items()}
    
    # Get generation params from handler if available
    max_new_tokens = handler_params.get('max_generation_length', 128)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=0.7,
            do_sample=True,
            top_p=0.9,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print(f"\nðŸ“ Prompt: {test_prompt}")
    print(f"ðŸ¤– Response: {response}")


def main():
    """Main training function."""
    parser = argparse.ArgumentParser(description="Universal Fine-tune model with LoRA")
    
    # Required arguments
    parser.add_argument("--data", type=str, required=True,
                       help="Path to training data (file or directory)")
    
    # Optional arguments
    parser.add_argument("--output", type=str, default="./lora",
                       help="Output directory for LoRA adapter")
    parser.add_argument("--model-path", type=str, default="./model",
                       help="Path to base model")
    
    # Training mode
    parser.add_argument("--mode", type=str, default="medium",
                       choices=["slow", "medium", "fast", "circle", "non-stop", "adaptive"],
                       help="Training mode")
    parser.add_argument("--method", type=str, default="lora",
                       choices=["lora", "qlora"],
                       help="Training method")
    
    # Training parameters
    parser.add_argument("--epochs", type=int, default=None,
                       help="Number of epochs (overrides mode default)")
    parser.add_argument("--batch-size", type=int, default=None,
                       help="Batch size (auto-detected if not set)")
    parser.add_argument("--learning-rate", type=float, default=None,
                       help="Learning rate (auto-detected if not set)")
    parser.add_argument("--lora-r", type=int, default=None,
                       help="LoRA rank (auto-detected if not set)")
    parser.add_argument("--lora-alpha", type=int, default=None,
                       help="LoRA alpha (default: 2*r)")
    
    # Data parameters
    parser.add_argument("--max-examples", type=int, default=0,
                       help="Maximum training examples (0 = all)")
    parser.add_argument("--validation-split", type=float, default=0.1,
                       help="Validation split ratio")
    parser.add_argument("--max-seq-length", type=int, default=None,
                       help="Maximum sequence length")
    parser.add_argument("--dataset-format", type=str, default="auto",
                       help="Dataset format (auto, alpaca, chat, etc.)")
    
    # Circular training
    parser.add_argument("--circular", action="store_true",
                       help="Enable circular training")
    parser.add_argument("--max-circular-epochs", type=int, default=100,
                       help="Maximum circular epochs")
    
    # Resume training
    parser.add_argument("--resume", action="store_true",
                       help="Resume from last checkpoint")
    parser.add_argument("--resume-from", type=str, default=None,
                       help="Resume from specific checkpoint")
    
    # Auto-stop parameters
    parser.add_argument("--patience", type=int, default=3,
                       help="Early stopping patience")
    parser.add_argument("--overfitting-threshold", type=float, default=0.1,
                       help="Overfitting detection threshold")
    
    # Hardware parameters
    parser.add_argument("--device", type=str, default="auto",
                       help="Device (auto/cuda/cpu)")
    parser.add_argument("--dtype", type=str, default="auto",
                       help="Data type (auto/float16/bfloat16/float32)")
    parser.add_argument("--use-8bit", action="store_true",
                       help="Use 8-bit quantization")
    parser.add_argument("--use-4bit", action="store_true",
                       help="Use 4-bit quantization")
    
    # Other parameters
    parser.add_argument("--test-prompt", type=str, 
                       default="Hello, how are you?",
                       help="Test prompt after training")
    parser.add_argument("--skip-test", action="store_true",
                       help="Skip testing after training")
    parser.add_argument("--seed", type=int, default=42,
                       help="Random seed")
    parser.add_argument("--force-epochs", action="store_true",
                       help="Force training for specified epochs, ignore auto-stop")
    
    args = parser.parse_args()
    
    # Set random seed
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # Load model info - check both locations
    model_info_path = Path("model_info.json")
    if not model_info_path.exists():
        # Try in model subdirectory
        model_info_path = Path(args.model_path) / "model_info.json"
        if not model_info_path.exists():
            raise FileNotFoundError(f"Model info not found in current directory or {model_info_path}")
    
    with open(model_info_path, 'r') as f:
        model_info = json.load(f)
    
    # Create training config
    from training_config import TrainingConfig
    
    config_kwargs = {
        'training_mode': args.mode,
        'method': args.method,
        'output_dir': args.output,
        'circular_training': args.circular,
        'max_circular_epochs': args.max_circular_epochs,
        'patience': args.patience,
        'overfitting_threshold': args.overfitting_threshold,
        'device': args.device,
        'dtype': args.dtype,
        'use_8bit': args.use_8bit,
        'use_4bit': args.use_4bit or args.method == 'qlora',
        'max_examples': args.max_examples if args.max_examples > 0 else None,
        'validation_split': args.validation_split,
        'dataset_format': args.dataset_format,
        'model_id': model_info.get('model_id', 'unknown'),
        'force_epochs': args.force_epochs,
    }
    
    # Add explicit parameters if provided
    if args.epochs is not None:
        config_kwargs['num_train_epochs'] = args.epochs
    if args.batch_size is not None:
        config_kwargs['batch_size'] = args.batch_size
    if args.learning_rate is not None:
        config_kwargs['learning_rate'] = args.learning_rate
    if args.lora_r is not None:
        config_kwargs['lora_r'] = args.lora_r
    if args.lora_alpha is not None:
        config_kwargs['lora_alpha'] = args.lora_alpha
    if args.max_seq_length is not None:
        config_kwargs['max_seq_length'] = args.max_seq_length
    if args.resume_from:
        config_kwargs['resume_from_checkpoint'] = args.resume_from
    elif args.resume:
        # Find last checkpoint
        checkpoint_dir = Path(args.output) / "checkpoints"
        if checkpoint_dir.exists():
            checkpoints = sorted(checkpoint_dir.glob("checkpoint-*"))
            if checkpoints:
                config_kwargs['resume_from_checkpoint'] = str(checkpoints[-1])
    
    training_config = TrainingConfig.from_model_info(model_info, **config_kwargs)
    
    # Print configuration
    print("\n" + "="*60)
    print("ðŸŽ¯ TRAINING CONFIGURATION")
    print("="*60)
    print(training_config.get_training_description())
    if args.force_epochs:
        print("\nðŸ”’ FORCE EPOCHS MODE ENABLED")
        print("   Training will continue for full epochs regardless of:")
        print("   - Overfitting detection")
        print("   - Early stopping")
        print("   - Perfect loss")
    print("="*60 + "\n")
    
    # Load model and tokenizer
    print("ðŸ“š Loading model and tokenizer...")
    model, tokenizer, handler, training_params = load_model_and_tokenizer(
        args.model_path, asdict(training_config), model_info
    )
    
    # Setup LoRA
    print("ðŸ”§ Setting up LoRA...")
    model = setup_lora(model, asdict(training_config), training_params)
    
    # Load dataset
    print("ðŸ“Š Loading dataset...")
    train_dataset, val_dataset = load_dataset(
        args.data, asdict(training_config), tokenizer, training_params
    )
    print(f"  Training examples: {len(train_dataset)}")
    if val_dataset:
        print(f"  Validation examples: {len(val_dataset)}")
    
    # Create output directory
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Start TensorBoard
    tb_process = None
    if 'tensorboard' in training_config.report_to:
        try:
            # Kill any existing TensorBoard process first
            subprocess.run(['pkill', '-f', 'tensorboard'], capture_output=True)
            time.sleep(1)  # Give it time to shut down
            
            tb_process = subprocess.Popen([
                'tensorboard',
                '--logdir', str(output_dir / "logs"),
                '--port', '6006',
                '--bind_all'
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            print(f"ðŸ“Š TensorBoard started at http://localhost:6006")
            print(f"   Monitoring logs at: {output_dir / 'logs'}")
        except Exception as e:
            logger.warning(f"Failed to start TensorBoard: {e}")
    
    try:
        # Create and run trainer
        trainer = SmartTrainer(
            model, tokenizer, train_dataset, val_dataset,
            asdict(training_config), output_dir, training_params
        )
        trainer.train()
        
        # Test model
        if not args.skip_test:
            test_model(args.model_path, args.output, args.test_prompt, training_params)
        
        print("\nâœ… Training completed successfully!")
        
    finally:
        # Cleanup
        if tb_process:
            tb_process.terminate()


if __name__ == "__main__":
    main()